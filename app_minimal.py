import os
import cv2
import numpy as np
from flask import Flask, request, jsonify, send_from_directory
from datetime import datetime
import base64
import traceback
import gc
import sys

print("=== Minimal YOLO API for 512MB RAM ===")

app = Flask(__name__, static_folder='static')

class MinimalYOLODetector:
    def __init__(self, model_path):
        """æç®€YOLOæ£€æµ‹å™¨ - ä¸“ä¸ºä½å†…å­˜è®¾è®¡"""
        self.model_path = model_path
        self.model = None
        self.model_loaded = False
        self.load_error = None
        self.load_model()

    def load_model(self):
        """åŠ è½½æ¨¡å‹ - å¸¦è¯¦ç»†é”™è¯¯å¤„ç†"""
        try:
            print(f"ğŸš€ å¼€å§‹åŠ è½½æ¨¡å‹...")
            print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {self.model_path}")
            print(f"ğŸ“‚ æ–‡ä»¶å­˜åœ¨: {os.path.exists(self.model_path)}")
            
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(self.model_path) / (1024*1024)  # MB
            print(f"ğŸ“Š æ¨¡å‹æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
            # æ˜¾ç¤ºå½“å‰å†…å­˜ä½¿ç”¨
            import psutil
            memory = psutil.virtual_memory()
            print(f"ğŸ§  ç³»ç»Ÿå†…å­˜: æ€»è®¡{memory.total//1024//1024}MB, å¯ç”¨{memory.available//1024//1024}MB")
            
            # å»¶è¿Ÿå¯¼å…¥ultralytics
            print("ğŸ“¦ å¯¼å…¥ultralytics...")
            from ultralytics import YOLO
            
            # æ¸…ç†å†…å­˜
            gc.collect()
            
            print("ğŸ”„ å¼€å§‹åŠ è½½YOLOæ¨¡å‹...")
            # å°è¯•åŠ è½½æ¨¡å‹ï¼Œé™åˆ¶è®¾å¤‡ä¸ºCPU
            self.model = YOLO(self.model_path, task='detect')
            
            # éªŒè¯æ¨¡å‹åŠ è½½
            if self.model is None:
                raise Exception("æ¨¡å‹å¯¹è±¡ä¸ºNone")
            
            self.model_loaded = True
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            print(f"ğŸ·ï¸  ç±»åˆ«æ•°é‡: {len(self.model.names)}")
            print(f"ğŸ”¤ ç±»åˆ«: {list(self.model.names.values())}")
            
            # å¼ºåˆ¶æ¸…ç†å†…å­˜
            gc.collect()
            
        except ImportError as e:
            error_msg = f"å¯¼å…¥ultralyticså¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.load_error = error_msg
            self.model_loaded = False
            
        except FileNotFoundError as e:
            error_msg = f"æ¨¡å‹æ–‡ä»¶é”™è¯¯: {e}"
            print(f"âŒ {error_msg}")
            self.load_error = error_msg
            self.model_loaded = False
            
        except MemoryError as e:
            error_msg = f"å†…å­˜ä¸è¶³: {e}"
            print(f"âŒ {error_msg}")
            self.load_error = error_msg
            self.model_loaded = False
            
        except Exception as e:
            error_msg = f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            print("ğŸ“‹ è¯¦ç»†é”™è¯¯:")
            traceback.print_exc()
            self.load_error = error_msg
            self.model_loaded = False

    def detect(self, image, conf_threshold=0.5, nms_threshold=0.4):
        """æ‰§è¡Œæ£€æµ‹"""
        if not self.model_loaded:
            raise Exception(f"æ¨¡å‹æœªåŠ è½½: {self.load_error}")
        
        try:
            print(f"ğŸ” å¼€å§‹æ£€æµ‹...")
            
            # å¼ºåˆ¶è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥èŠ‚çœå†…å­˜
            height, width = image.shape[:2]
            max_size = 416  # ä½¿ç”¨æ›´å°çš„å°ºå¯¸
            if width > max_size or height > max_size:
                scale = max_size / max(width, height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                image = cv2.resize(image, (new_width, new_height))
                print(f"ğŸ“ å›¾ç‰‡è°ƒæ•´: {width}x{height} -> {new_width}x{new_height}")
            
            # æ‰§è¡Œæ£€æµ‹
            results = self.model(image, conf=conf_threshold, iou=nms_threshold, verbose=False)
            
            predictions = []
            if results and len(results) > 0:
                result = results[0]
                if result.boxes is not None and len(result.boxes) > 0:
                    boxes = result.boxes
                    for i in range(len(boxes)):
                        box = boxes.xyxy[i].cpu().numpy()
                        x1, y1, x2, y2 = map(int, box)
                        confidence = float(boxes.conf[i].cpu().numpy())
                        class_id = int(boxes.cls[i].cpu().numpy())
                        class_name = self.model.names.get(class_id, f'class_{class_id}')
                        
                        predictions.append({
                            'bbox': [x1, y1, x2, y2],
                            'confidence': confidence,
                            'class_id': class_id,
                            'class_name': class_name
                        })
            
            print(f"âœ… æ£€æµ‹å®Œæˆ: {len(predictions)} ä¸ªç›®æ ‡")
            gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
            return predictions
            
        except Exception as e:
            print(f"âŒ æ£€æµ‹å¼‚å¸¸: {e}")
            traceback.print_exc()
            return []

# å…¨å±€æ£€æµ‹å™¨
detector = None

@app.route('/')
def index():
    return send_from_directory('static', 'index.html')

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'model_loaded': detector.model_loaded if detector else False,
        'model_type': 'PyTorch (.pt)',
        'model_classes': detector.model.names if detector and detector.model_loaded else None,
        'load_error': detector.load_error if detector else None,
        'model_path_exists': os.path.exists(os.getenv('MODEL_PATH', '/app/models/best.pt'))
    })

@app.route('/debug', methods=['GET'])
def debug_info():
    """è¯¦ç»†è°ƒè¯•ä¿¡æ¯"""
    model_path = os.getenv('MODEL_PATH', '/app/models/best.pt')
    
    debug_data = {
        'model_path': model_path,
        'model_path_exists': os.path.exists(model_path),
        'working_directory': os.getcwd(),
        'python_version': sys.version,
        'model_loaded': detector.model_loaded if detector else False,
        'load_error': detector.load_error if detector else None,
        'env_vars': {
            'MODEL_PATH': os.getenv('MODEL_PATH'),
            'PORT': os.getenv('PORT'),
            'PYTHONUNBUFFERED': os.getenv('PYTHONUNBUFFERED')
        }
    }
    
    # æ–‡ä»¶ä¿¡æ¯
    if os.path.exists(model_path):
        debug_data['model_file_size_mb'] = round(os.path.getsize(model_path) / (1024*1024), 2)
    
    # å†…å­˜ä¿¡æ¯
    try:
        import psutil
        memory = psutil.virtual_memory()
        debug_data['memory'] = {
            'total_mb': memory.total // 1024 // 1024,
            'available_mb': memory.available // 1024 // 1024,
            'used_mb': memory.used // 1024 // 1024,
            'percent': memory.percent
        }
    except ImportError:
        debug_data['memory'] = 'psutil not available'
    
    # ç›®å½•ä¿¡æ¯
    try:
        debug_data['app_directory'] = os.listdir('/app') if os.path.exists('/app') else 'not exists'
        debug_data['models_directory'] = os.listdir('/app/models') if os.path.exists('/app/models') else 'not exists'
    except Exception as e:
        debug_data['directory_error'] = str(e)
    
    return jsonify(debug_data)

@app.route('/detect', methods=['POST'])
def detect_objects():
    global detector
    
    if not detector or not detector.model_loaded:
        error_msg = detector.load_error if detector else "æ£€æµ‹å™¨æœªåˆå§‹åŒ–"
        return jsonify({'error': f'æ¨¡å‹æœªåŠ è½½: {error_msg}'}), 500
    
    try:
        image = None
        
        if 'image' in request.files:
            file = request.files['image']
            image_bytes = file.read()
            image_array = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
        elif request.is_json and 'image_base64' in request.json:
            image_base64 = request.json['image_base64']
            image_bytes = base64.b64decode(image_base64)
            image_array = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
        else:
            return jsonify({'error': 'è¯·æä¾›å›¾åƒæ–‡ä»¶æˆ–Base64ç¼–ç çš„å›¾åƒ'}), 400
        
        if image is None:
            return jsonify({'error': 'æ— æ³•è§£æå›¾åƒ'}), 400
        
        conf_threshold = request.json.get('conf_threshold', 0.5) if request.is_json else float(request.form.get('conf_threshold', 0.5))
        nms_threshold = request.json.get('nms_threshold', 0.4) if request.is_json else float(request.form.get('nms_threshold', 0.4))
        
        predictions = detector.detect(image, conf_threshold, nms_threshold)
        
        result = {
            'success': True,
            'predictions': predictions,
            'total_detections': len(predictions),
            'timestamp': datetime.now().isoformat(),
            'model_type': 'PyTorch (.pt)'
        }
        
        return jsonify(result)
        
    except Exception as e:
        print("âŒ æ£€æµ‹å¼‚å¸¸:", e)
        traceback.print_exc()
        return jsonify({'error': f'æ£€æµ‹å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    model_path = os.getenv('MODEL_PATH', '/app/models/best.pt')
    
    print(f"ğŸš€ å¯åŠ¨æç®€YOLO API...")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"ğŸŒ ç¯å¢ƒå˜é‡: {dict(os.environ)}")
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = MinimalYOLODetector(model_path)
    
    # å¯åŠ¨Flaskåº”ç”¨
    port = int(os.getenv('PORT', 5000))
    print(f"ğŸŒ å¯åŠ¨WebæœåŠ¡ï¼Œç«¯å£: {port}")
    app.run(host='0.0.0.0', port=port, debug=False) 